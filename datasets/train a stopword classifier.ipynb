{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import sklearn\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data\n",
    "\n",
    "- training set and cross-validation set\n",
    "- compute features\n",
    "- pre-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6970\n"
     ]
    }
   ],
   "source": [
    "entries = [ \"Plato\", \"Martin_Heidegger\", \"Ludwig_Wittgenstein\", \"Bruno_Latour\", \"René_Descartes\", \"Immanuel_Kant\" ]\n",
    "\n",
    "def build_corpus(entries):\n",
    "  corpus = []\n",
    "\n",
    "  for e in entries:\n",
    "    txt = codecs.open(\"pages/%s.html\" % e,\"r\", \"utf-8-sig\").read()\n",
    "\n",
    "    txt = BeautifulSoup(txt, \"html.parser\")\n",
    "    txt = txt.get_text()\n",
    "\n",
    "    sentences = txt.split(\".\")\n",
    "\n",
    "    corpus.extend(sentences)\n",
    "    \n",
    "  return corpus\n",
    "\n",
    "corpus = build_corpus(entries)\n",
    "\n",
    "print len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part-of-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104543\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "def tokenize(sentence):\n",
    "  tokens = []\n",
    "  \n",
    "  text_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "  \n",
    "  return text_tagged\n",
    "\n",
    "tokens = reduce(lambda a,b: a + b, map(tokenize, corpus))\n",
    "\n",
    "# print tokens\n",
    "print len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Heidegger', 'NNP'),\n",
       " (u'Thoughts', 'NNS'),\n",
       " (u'Meta-', 'NNP'),\n",
       " (u'by', 'IN'),\n",
       " (u'of', 'IN'),\n",
       " (u'the', 'DT'),\n",
       " (u',', ','),\n",
       " (u'this', 'DT'),\n",
       " (u'Marijan', 'NNP'),\n",
       " (u'of', 'IN'),\n",
       " (u'as', 'IN'),\n",
       " (u'does', 'VBZ'),\n",
       " (u'works', 'NNS'),\n",
       " (u'theory', 'NN'),\n",
       " (u'German', 'JJ'),\n",
       " (u'Earlier', 'JJR'),\n",
       " (u'\\xa738', 'NN'),\n",
       " (u')', ')'),\n",
       " (u'morphism', 'NN'),\n",
       " (u'Studies', 'NNS')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(tokens)\n",
    "\n",
    "tokens[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ parts, tags ] = zip(*tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags_classes = set(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRP$</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBD</th>\n",
       "      <th>``</th>\n",
       "      <th>VBN</th>\n",
       "      <th>POS</th>\n",
       "      <th>''</th>\n",
       "      <th>VBP</th>\n",
       "      <th>WDT</th>\n",
       "      <th>JJ</th>\n",
       "      <th>...</th>\n",
       "      <th>CD</th>\n",
       "      <th>EX</th>\n",
       "      <th>IN</th>\n",
       "      <th>WP$</th>\n",
       "      <th>MD</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>JJS</th>\n",
       "      <th>JJR</th>\n",
       "      <th>SYM</th>\n",
       "      <th>UH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Exact</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebular</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberty</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRP$  VBG  VBD   ``  VBN  POS   ''  VBP  WDT   JJ ...    CD   EX   IN  \\\n",
       "Exact    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "Nebular  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN    1 ...   NaN  NaN  NaN   \n",
       "Liberty  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "ORB      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "Alexy    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "\n",
       "         WP$   MD NNPS  JJS  JJR  SYM   UH  \n",
       "Exact    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "Nebular  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "Liberty  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "ORB      NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "Alexy    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = list(tags_classes))\n",
    "\n",
    "for i in set(tokens):\n",
    "  df.loc[i[0],i[1]] = 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14204\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"length\"] = map(lambda x: len(x), df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRP$</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBD</th>\n",
       "      <th>``</th>\n",
       "      <th>VBN</th>\n",
       "      <th>POS</th>\n",
       "      <th>''</th>\n",
       "      <th>VBP</th>\n",
       "      <th>WDT</th>\n",
       "      <th>JJ</th>\n",
       "      <th>...</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>JJS</th>\n",
       "      <th>JJR</th>\n",
       "      <th>SYM</th>\n",
       "      <th>UH</th>\n",
       "      <th>length</th>\n",
       "      <th>occurences</th>\n",
       "      <th>frequency</th>\n",
       "      <th>digits</th>\n",
       "      <th>~ name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Exact</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebular</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberty</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devastating</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Note</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dostoevsky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corrections</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bambach</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRP$  VBG  VBD  ``  VBN  POS  ''  VBP  WDT  JJ   ...    NNPS  \\\n",
       "Exact           0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "Nebular         0    0    0   0    0    0   0    0    0   1   ...       0   \n",
       "Liberty         0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "ORB             0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "Alexy           0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "devastating     0    0    0   0    0    0   0    0    0   1   ...       0   \n",
       "Note            0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "Dostoevsky      0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "corrections     0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "Bambach         0    0    0   0    0    0   0    0    0   0   ...       0   \n",
       "\n",
       "             JJS  JJR  SYM  UH  length  occurences  frequency  digits  ~ name  \n",
       "Exact          0    0    0   0       5         1.0   0.000010       0   False  \n",
       "Nebular        0    0    0   0       7         1.0   0.000010       0   False  \n",
       "Liberty        0    0    0   0       7         5.0   0.000048       0   False  \n",
       "ORB            0    0    0   0       3         1.0   0.000010       0   False  \n",
       "Alexy          0    0    0   0       5         1.0   0.000010       0    True  \n",
       "devastating    0    0    0   0      11         1.0   0.000010       0   False  \n",
       "Note           0    0    0   0       4         3.0   0.000029       0   False  \n",
       "Dostoevsky     0    0    0   0      10         1.0   0.000010       0   False  \n",
       "corrections    0    0    0   0      11         3.0   0.000029       0   False  \n",
       "Bambach        0    0    0   0       7         1.0   0.000010       0   False  \n",
       "\n",
       "[10 rows x 48 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter=collections.Counter(parts)\n",
    "n = len(parts)\n",
    "\n",
    "# print df.iloc[0:10,0].index\n",
    "df[\"occurences\"] = map(lambda x: float(counter[x]), df.index)\n",
    "df[\"frequency\"] = map(lambda x: float(counter[x])/float(n), df.index)\n",
    "\n",
    "df.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3591"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"digits\"] = map(lambda w: sum([l.isdigit() for l in w]), df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Muhammad', 'Mustafa', 'Jauhar', 'Leonardo', 'Polo', 'Abd', 'al-Rahman', 'al-Kawakibi', u'Jaime', u'Guzm\\xe1n', 'Jodi', 'Dean', 'Pietro', 'Verri', 'David', 'Dowty', u'Ivo', u'Urban\\u010di\\u010d', 'Raoul', 'Vaneigem']\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_gexf(\"influences.gexf\")\n",
    "\n",
    "names = reduce(lambda a,b: a + b, [ n.split(\"_\") for n in G.nodes() ])\n",
    "print names[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"~ name\"] = map(lambda w: int(w in names), df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistisc regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "stopwords_base = codecs.open(\"stopwords.txt\", \"r\", \"utf-8\").read().split()\n",
    "print len(stopwords_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print len( set(df.index.unique()) & set(stopwords_base) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "df2[\"stopword\"] = 0\n",
    "\n",
    "df2.loc[list(set(df.index.unique()) & set(stopwords_base)), [\"stopword\"]] = 1\n",
    "\n",
    "print len(df2[df2[\"stopword\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRP$</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBD</th>\n",
       "      <th>``</th>\n",
       "      <th>VBN</th>\n",
       "      <th>POS</th>\n",
       "      <th>''</th>\n",
       "      <th>VBP</th>\n",
       "      <th>WDT</th>\n",
       "      <th>JJ</th>\n",
       "      <th>...</th>\n",
       "      <th>JJS</th>\n",
       "      <th>JJR</th>\n",
       "      <th>SYM</th>\n",
       "      <th>UH</th>\n",
       "      <th>length</th>\n",
       "      <th>occurences</th>\n",
       "      <th>frequency</th>\n",
       "      <th>digits</th>\n",
       "      <th>~ name</th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Exact</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebular</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberty</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRP$  VBG  VBD  ``  VBN  POS  ''  VBP  WDT  JJ    ...     JJS  JJR  \\\n",
       "Exact       0    0    0   0    0    0   0    0    0   0    ...       0    0   \n",
       "Nebular     0    0    0   0    0    0   0    0    0   1    ...       0    0   \n",
       "Liberty     0    0    0   0    0    0   0    0    0   0    ...       0    0   \n",
       "ORB         0    0    0   0    0    0   0    0    0   0    ...       0    0   \n",
       "Alexy       0    0    0   0    0    0   0    0    0   0    ...       0    0   \n",
       "\n",
       "         SYM  UH  length  occurences  frequency  digits  ~ name  stopword  \n",
       "Exact      0   0       5         1.0   0.000010       0       0         0  \n",
       "Nebular    0   0       7         1.0   0.000010       0       0         0  \n",
       "Liberty    0   0       7         5.0   0.000048       0       0         0  \n",
       "ORB        0   0       3         1.0   0.000010       0       0         0  \n",
       "Alexy      0   0       5         1.0   0.000010       0       1         0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "train1 = df2[df2[\"stopword\"] == 1]\n",
    "train1 = train1.append(df2[df2[\"stopword\"] == 0].iloc[0:128,:])\n",
    "\n",
    "print len(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codecs.open(\"stopwords.training.txt\", \"w\", \"utf-8\").write(\"\\n\".join(train1.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=1e-06,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [ c for c in train1.columns if c != \"stopword\" ]\n",
    "\n",
    "X = train1.loc[:,features]\n",
    "X_normalized = sklearn.preprocessing.normalize(X, norm='l1')\n",
    "Y = train1[\"stopword\"].as_matrix()\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(penalty='l1', tol=1e-6, solver=\"liblinear\")\n",
    "clf.fit(X_normalized, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv1 = df2.loc[[ index for index in df2.index if index not in train1.index ],:] \n",
    "cv1 = cv1.iloc[0:1000,:]\n",
    "\n",
    "cv1_ypredict = clf.predict(sklearn.preprocessing.normalize(cv1.loc[:, features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "cv1[\"stopword_predict\"] = cv1_ypredict\n",
    "\n",
    "print len(cv1[cv1[\"stopword_predict\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u']', u'René', u'26', u'after', u'work', u'Was', u'used', u'fact', u'O',\n",
      "       u'most', u'44', u'London', u''', u'1991', u'd', u'la', u'knowledge',\n",
      "       u'later', u'32', u'Works', u'Plato', u'22', u'These', u'11', u'France',\n",
      "       u'The', u'G', u'New', u'told', u'45', u'y', u'end', u'”', u'up',\n",
      "       u'form', u'Hitler', u'Vol', u'much', u'Athens', u'text', u'8', u'2012',\n",
      "       u'If', u'–', u'argued'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print cv1[cv1[\"stopword_predict\"] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"stopwords.cv.generated.txt\", \"w\", \"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(cv1[cv1[\"stopword_predict\"] == 1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"stopwords.cv.generated.n.txt\", \"w\", \"utf-8\") as f:\n",
    "  f.write(\"\\n\".join(cv1[cv1[\"stopword_predict\"] == 0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_fp = codecs.open(\"stopwords.cv.control-fp.txt\", \"r\", \"utf-8\").read().split()\n",
    "cv_fn = codecs.open(\"stopwords.cv.control-fn.txt\", \"r\", \"utf-8\").read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv1[\"stopword\"] = cv1[\"stopword_predict\"]\n",
    "\n",
    "cv1.loc[[ w for w in cv_fp if w in cv1.index],\"stopword\"] = 0\n",
    "cv1.loc[[ w for w in cv_fn if w in cv1.index],\"stopword\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=1e-06,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = train1.append(cv1)\n",
    "\n",
    "X2 = train2.loc[:, features]\n",
    "Y2 = train2[\"stopword\"]\n",
    "\n",
    "clf2 = sklearn.linear_model.LogisticRegression(penalty='l1', tol=1e-6, solver=\"liblinear\")\n",
    "clf2.fit(sklearn.preprocessing.normalize(X2), Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2 = df2.loc[[ index for index in df2.index if index not in train2.index ],:] \n",
    "cv2 = cv2.iloc[0:1000,:]\n",
    "\n",
    "cv2_ypredict = clf2.predict(sklearn.preprocessing.normalize(cv2.loc[:, features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "cv2[\"stopword_predict\"] = cv2_ypredict\n",
    "\n",
    "print len(cv2[cv2[\"stopword_predict\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'good', u'1889-04-26', u'382–384', u'[', u'978-2-84066-557-1', u'984',\n",
      "       u'6', u'027076164', u'374', u'et', u'de', u'reason', u'1889—1951',\n",
      "       u'Descartes', u'231', u'9783832926045', u'1682–1746', u'Cambridge',\n",
      "       u'jn19990009594', u'V', u'119404923', u'1911-1951', u'1904', u'277',\n",
      "       u'our', u'135–145', u'1635–36', u'1890', u'Retrieved', u'ethics',\n",
      "       u'ISBN', u'258–289', u'0-87220-349-2', u'1643', u'0-674-92905-5', u'—',\n",
      "       u'800', u'1-4184-4977-6', u'167', u'19', u'2849', u'313', u'421',\n",
      "       u'1950–51', u'''', u'because', u'978-1-930972-09-4', u'145–146',\n",
      "       u'2013', u'0-486-41605-4', u'309', u'500248317', u'0-253-21800-4', u'§',\n",
      "       u'H', u'0266-9080', u'This', u'2009', u'John', u'1927–1961', u'373–377',\n",
      "       u'As', u'0-19-508645-7', u'His', u'Socrates', u'293–303', u'must',\n",
      "       u'law', u'1745–47', u'978-1-930972-79-7', u'02694507X',\n",
      "       u'0-271-02083-0', u'e', u'1889–1936', u'1936/7', u'ed', u'1750–58'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print cv2[cv2[\"stopword_predict\"] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'Socrates', u'good', u'reason', u'law', u'Descartes'])\n"
     ]
    }
   ],
   "source": [
    "print set(cv2[cv2[\"stopword_predict\"] == 1].index) & set(cv_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2192\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "final = train2.append(cv2)\n",
    "\n",
    "print len(final)\n",
    "print len(final[final[\"stopword\"] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.loc[list(set(cv2[cv2[\"stopword_predict\"] == 1].index) & set(cv_fp)),\"stopword\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codecs.open(\"stopwords.final.txt\", \"w\", \"utf-8\").write(\"\\n\".join(final[final[\"stopword\"] == 1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805\n",
      "Index([u'0-521-64836-X', u'see', u'1748', u'510', u'4025', u'1947–1951',\n",
      "       u'180', u'und', u'28', u'W',\n",
      "       ...\n",
      "       u'1700', u'1615–16', u'0-691-02391-3', u'But', u'1634–35', u'am',\n",
      "       u'119–24', u'9780674043237', u'1163/156852880x00025', u'135798642'],\n",
      "      dtype='object', length=805)\n"
     ]
    }
   ],
   "source": [
    "test = df.loc[[ w for w in df.index if w not in final.index], :]\n",
    "\n",
    "test_ypredict = clf2.predict(sklearn.preprocessing.normalize(test.loc[:, features]))\n",
    "\n",
    "test[\"stopword_predict\"] = test_ypredict\n",
    "\n",
    "print len(test[test[\"stopword_predict\"] == 1])\n",
    "print test[test[\"stopword_predict\"] == 1].index\n",
    "\n",
    "codecs.open(\"stopwords.test.p.txt\", \"w\", \"utf-8\").write(\"\\n\".join(test[test[\"stopword_predict\"] == 1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14204\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "\n",
    "all_predict = clf2.predict(sklearn.preprocessing.normalize(df.loc[:, features]))\n",
    "\n",
    "df3[\"stopword_predict\"] = all_predict\n",
    "\n",
    "codecs.open(\"stopwords.all.p.txt\", \"w\", \"utf-8\").write(\"\\n\".join(df3[(df3[\"stopword_predict\"] == 1) & (df3[\"~ name\"] == False)].index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
