<p>
</p>
<table class="infobox vcard" style="width:22em"><tr><th colspan="2" style="text-align:center;font-size:125%;font-weight:bold"><span class="fn">Nick Bostrom</span></th></tr><tr><td colspan="2" style="text-align:center;padding-bottom:0.5em;">
<a href="/wiki/File:Nick_Bostrom.jpg" class="image"><img alt="Nick Bostrom.jpg" src="//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Nick_Bostrom.jpg/220px-Nick_Bostrom.jpg" width="220" height="201" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Nick_Bostrom.jpg/330px-Nick_Bostrom.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Nick_Bostrom.jpg/440px-Nick_Bostrom.jpg 2x" data-file-width="546" data-file-height="498" /></a><div>Nick Bostrom, 2006</div></td></tr><tr><th scope="row">Born</th><td>
Niklas Boström<br/><span style="display:none"> (<span class="bday">1973-03-10</span>) </span>10 March 1973<span class="noprint ForceAgeToShow"> (age&#160;43)</span><br/><a href="/wiki/Helsingborg" title="Helsingborg">Helsingborg</a>, Sweden</td></tr><tr><th scope="row"><span class="nowrap"><a href="/wiki/Alma_mater" title="Alma mater">Alma mater</a></span></th><td>
<div class="plainlist"><ul><li><a href="/wiki/University_of_Gothenburg" title="University of Gothenburg">University of Gothenburg</a> (B.A.)</li><li><a href="/wiki/Stockholm_University" title="Stockholm University">Stockholm University</a> (M.A.)</li><li><a href="/wiki/King%27s_College_London" title="King's College London">King's College London</a> (M.Sc.)</li><li><a href="/wiki/London_School_of_Economics" title="London School of Economics">London School of Economics</a> (Ph.D.)</li></ul></div></td></tr><tr><th scope="row"><a href="/wiki/Thesis" title="Thesis">Thesis</a></th><td>
<a rel="nofollow" class="external text" href="http://etheses.lse.ac.uk/2642/"><i>Observational Selection Effects and Probability</i></a></td></tr><tr><th scope="row">Known&#160;for</th><td>
<i><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></i>,<br/><a href="/wiki/Existential_risk" title="Existential risk" class="mw-redirect">existential risk</a>, <a href="/wiki/Anthropic_bias" title="Anthropic bias" class="mw-redirect">anthropic bias</a>, the <a href="/wiki/Reversal_test" title="Reversal test">reversal test</a>, the <a href="/wiki/Simulation_hypothesis" title="Simulation hypothesis">simulation hypothesis</a>, ethical <a href="/wiki/Consequentialism" title="Consequentialism">consequentialism</a></td></tr><tr><th scope="row">Notable awards</th><td>
<div class="plainlist">
<ul><li> Professorial Distinction Award from University of Oxford</li>
<li> <a href="/wiki/FP_Top_100_Global_Thinkers" title="FP Top 100 Global Thinkers">FP Top 100 Global Thinkers</a></li>
<li> <i><a href="/wiki/Prospect_(magazine)" title="Prospect (magazine)">Prospect</a></i><span class="nowrap" style="padding-left:0.1em;">&#39;</span>s Top World Thinker list</li></ul>
</div></td></tr><tr><td colspan="2" style="text-align:center">
<b>Website</b><br/><span class="url"><a rel="nofollow" class="external text" href="http://nickbostrom.com">NickBostrom<wbr/>.com</a></span></td></tr></table>
<p><b>Nick Bostrom</b> (Swedish: <b>Niklas Boström</b>; born 10 March 1973)<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">[1]</a></sup> is a Swedish <a href="/wiki/Philosophy" title="Philosophy">philosopher</a> at the <a href="/wiki/University_of_Oxford" title="University of Oxford">University of Oxford</a> known for his work on <a href="/wiki/Existential_risk" title="Existential risk" class="mw-redirect">existential risk</a>, the <a href="/wiki/Anthropic_principle" title="Anthropic principle">anthropic principle</a>, <a href="/wiki/Human_enhancement" title="Human enhancement">human enhancement</a> ethics, <a href="/wiki/Superintelligence" title="Superintelligence">superintelligence</a> risks, the <a href="/wiki/Reversal_test" title="Reversal test">reversal test</a>, and <a href="/wiki/Consequentialism" title="Consequentialism">consequentialism</a>. He holds a <a href="/wiki/Doctor_of_Philosophy" title="Doctor of Philosophy">PhD</a> from the <a href="/wiki/London_School_of_Economics" title="London School of Economics">London School of Economics</a> (2000). In 2011, he founded the Oxford Martin Programme on the Impacts of Future Technology,<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">[2]</a></sup> and he is currently the founding director of the <a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a><sup id="cite_ref-3" class="reference"><a href="#cite_note-3">[3]</a></sup> at Oxford University.
</p><p>He is the author of over 200 publications,<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">[4]</a></sup> including <i><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></i> (2014), a <i>New York Times</i> bestseller<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">[5]</a></sup> and <i><a href="/wiki/Anthropic_Bias:_Observation_Selection_Effects_in_Science_and_Philosophy" title="Anthropic Bias: Observation Selection Effects in Science and Philosophy">Anthropic Bias: Observation Selection Effects in Science and Philosophy</a></i> (2002).<sup id="cite_ref-Oxford_University_Press_6-0" class="reference"><a href="#cite_note-Oxford_University_Press-6">[6]</a></sup> In 2009 and 2015, he was included in <i><a href="/wiki/Foreign_Policy" title="Foreign Policy">Foreign Policy</a></i><span class="nowrap" style="padding-left:0.1em;">&#39;</span> <a href="/wiki/FP_Top_100_Global_Thinkers" title="FP Top 100 Global Thinkers">Top 100 Global Thinkers</a> list.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">[7]</a></sup><sup id="cite_ref-8" class="reference"><a href="#cite_note-8">[8]</a></sup> Bostrom's work on <a href="/wiki/Superintelligence" title="Superintelligence">superintelligence</a> – and his concern for its existential risk to humanity over the coming century – has brought both <a href="/wiki/Elon_Musk" title="Elon Musk">Elon Musk</a> and <a href="/wiki/Bill_Gates" title="Bill Gates">Bill Gates</a> to similar thinking.<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">[9]</a></sup><sup id="cite_ref-10" class="reference"><a href="#cite_note-10">[10]</a></sup><sup id="cite_ref-11" class="reference"><a href="#cite_note-11">[11]</a></sup>
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Biography"><span class="tocnumber">1</span> <span class="toctext">Biography</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Philosophy"><span class="tocnumber">2</span> <span class="toctext">Philosophy</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Existential_risk"><span class="tocnumber">2.1</span> <span class="toctext">Existential risk</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Superintelligence"><span class="tocnumber">2.2</span> <span class="toctext">Superintelligence</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Anthropic_reasoning"><span class="tocnumber">2.3</span> <span class="toctext">Anthropic reasoning</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Ethics_of_human_enhancement"><span class="tocnumber">2.4</span> <span class="toctext">Ethics of human enhancement</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Technology_strategy"><span class="tocnumber">2.5</span> <span class="toctext">Technology strategy</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Simulation_argument"><span class="tocnumber">2.6</span> <span class="toctext">Simulation argument</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="#Policy_and_consultations"><span class="tocnumber">3</span> <span class="toctext">Policy and consultations</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#See_also"><span class="tocnumber">4</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Bibliography"><span class="tocnumber">5</span> <span class="toctext">Bibliography</span></a>
<ul>
<li class="toclevel-2 tocsection-12"><a href="#Books"><span class="tocnumber">5.1</span> <span class="toctext">Books</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#Journal_articles_.28selected.29"><span class="tocnumber">5.2</span> <span class="toctext">Journal articles (selected)</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-14"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#External_links"><span class="tocnumber">7</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Biography">Biography</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=1" title="Edit section: Biography">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Bostrom was born in 1973 in <a href="/wiki/Helsingborg" title="Helsingborg">Helsingborg</a>, Sweden.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">[12]</a></sup> At a young age, he disliked school, and he ended up spending his last year of high school learning from home. He sought to educate himself in a wide variety of disciplines, including anthropology, art, literature, and science.<sup id="cite_ref-newyorker_13-0" class="reference"><a href="#cite_note-newyorker-13">[13]</a></sup>
</p><p>He holds a B.A. in philosophy, mathematics, mathematical logic, and artificial intelligence from the <a href="/wiki/University_of_Gothenburg" title="University of Gothenburg">University of Gothenburg</a> and master's degrees in philosophy and physics, and <a href="/wiki/Computational_neuroscience" title="Computational neuroscience">computational neuroscience</a> from <a href="/wiki/Stockholm_University" title="Stockholm University">Stockholm University</a> and <a href="/wiki/King%27s_College_London" title="King's College London">King's College London</a>, respectively. During his time at Stockholm University, he researched the relationship between language and reality by studying the analytic philosopher <a href="/wiki/W.V._Quine" title="W.V. Quine" class="mw-redirect">W.V. Quine</a>.<sup id="cite_ref-newyorker_13-1" class="reference"><a href="#cite_note-newyorker-13">[13]</a></sup> In 2000, he was awarded a PhD in philosophy from the <a href="/wiki/London_School_of_Economics" title="London School of Economics">London School of Economics</a>. He held a teaching position at <a href="/wiki/Yale_University" title="Yale University">Yale University</a> (2000–2002), and he was a <a href="/wiki/British_Academy" title="British Academy">British Academy</a> Postdoctoral Fellow at the University of Oxford (2002–2005).<sup id="cite_ref-Oxford_University_Press_6-1" class="reference"><a href="#cite_note-Oxford_University_Press-6">[6]</a></sup><sup id="cite_ref-14" class="reference"><a href="#cite_note-14">[14]</a></sup>
</p>
<h2><span class="mw-headline" id="Philosophy">Philosophy</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=2" title="Edit section: Philosophy">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Existential_risk">Existential risk</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=3" title="Edit section: Existential risk">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>An important aspect of Bostrom's research concerns the future of humanity and long-term outcomes.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">[15]</a></sup><sup id="cite_ref-Andersen_16-0" class="reference"><a href="#cite_note-Andersen-16">[16]</a></sup> He introduced the concept of an <a href="/wiki/Existential_risk" title="Existential risk" class="mw-redirect">existential risk</a>, which he defines as one in which an "adverse outcome would either annihilate Earth-originating intelligent life or permanently and drastically curtail its potential." In the 2008 volume <i><a href="/wiki/Global_Catastrophic_Risks_(book)" title="Global Catastrophic Risks (book)">Global Catastrophic Risks</a></i>, editors Bostrom and Milan Ćirković characterize the relation between existential risk and the broader class of global catastrophic risks, and link existential risk to <a href="/wiki/Selection_bias#Observer_selection" title="Selection bias">observer selection effects</a><sup id="cite_ref-17" class="reference"><a href="#cite_note-17">[17]</a></sup> and the <a href="/wiki/Fermi_paradox" title="Fermi paradox">Fermi paradox</a>.<sup id="cite_ref-18" class="reference"><a href="#cite_note-18">[18]</a></sup><sup id="cite_ref-NYT-20150803_19-0" class="reference"><a href="#cite_note-NYT-20150803-19">[19]</a></sup> In a 2013 paper in the journal <i><a href="/wiki/Global_Policy" title="Global Policy">Global Policy</a></i>, Bostrom offers a taxonomy of existential risk and proposes a reconceptualization of sustainability in dynamic terms, as a developmental trajectory that minimizes existential risk.<sup id="cite_ref-20" class="reference"><a href="#cite_note-20">[20]</a></sup>
</p><p>The philosopher <a href="/wiki/Derek_Parfit" title="Derek Parfit">Derek Parfit</a> argued for the importance of ensuring the survival of humanity, due to the value of a potentially large number of future generations.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">[21]</a></sup> Similarly, Bostrom has said that, from a <a href="/wiki/Consequentialism" title="Consequentialism">consequentialist</a> perspective, even small reductions in the cumulative amount of existential risk that humanity will face are extremely valuable, to the point where the traditional utilitarian imperative—to maximize expected utility—can be simplified to the Maxipok principle: maximize the probability of an OK outcome (where an OK outcome is any that avoids existential catastrophe).<sup id="cite_ref-22" class="reference"><a href="#cite_note-22">[22]</a></sup><sup id="cite_ref-23" class="reference"><a href="#cite_note-23">[23]</a></sup>
</p><p>In 2005, Bostrom founded the <a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a>,<sup id="cite_ref-newyorker_13-2" class="reference"><a href="#cite_note-newyorker-13">[13]</a></sup> which researches the far future of human civilization. He is also an adviser to the <a href="/wiki/Centre_for_the_Study_of_Existential_Risk" title="Centre for the Study of Existential Risk">Centre for the Study of Existential Risk</a>.<sup id="cite_ref-Andersen_16-1" class="reference"><a href="#cite_note-Andersen-16">[16]</a></sup>
</p>
<h3><span class="mw-headline" id="Superintelligence">Superintelligence</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=4" title="Edit section: Superintelligence">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In his 2014 book <i><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></i>, Bostrom reasons that with "cognitive performance greatly [exceeding] that of humans in virtually all domains of interest", <a href="/wiki/Superintelligent" title="Superintelligent" class="mw-redirect">superintelligent</a> agents could promise substantial societal benefits and pose a significant <a href="/wiki/Existential_risk_from_advanced_artificial_intelligence" title="Existential risk from advanced artificial intelligence" class="mw-redirect">artificial intelligence (AI)-related existential risk</a>. Therefore, it is crucial (he says) that we approach this area with caution, and take active steps to mitigate the risks we face. In January 2015, Bostrom joined <a href="/wiki/Stephen_Hawking" title="Stephen Hawking">Stephen Hawking</a>, <a href="/wiki/Max_Tegmark" title="Max Tegmark">Max Tegmark</a>, <a href="/wiki/Elon_Musk" title="Elon Musk">Elon Musk</a>, <a href="/wiki/Martin_Rees" title="Martin Rees">Martin Rees</a>, <a href="/wiki/Jaan_Tallinn" title="Jaan Tallinn">Jaan Tallinn</a> among others, in signing the <a href="/wiki/Future_of_Life_Institute" title="Future of Life Institute">Future of Life Institute</a>'s open letter warning of the potential dangers of AI. The signatories "...believe that research on how to make AI systems robust and beneficial is both important and timely, and that there are concrete research directions that can be pursued today."<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">[24]</a></sup><sup id="cite_ref-25" class="reference"><a href="#cite_note-25">[25]</a></sup>
</p>
<h3><span class="mw-headline" id="Anthropic_reasoning">Anthropic reasoning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=5" title="Edit section: Anthropic reasoning">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Bostrom has published numerous articles on <a href="/wiki/Anthropic_principle" title="Anthropic principle">anthropic reasoning</a>, as well as the book <i><a href="/wiki/Anthropic_Bias:_Observation_Selection_Effects_in_Science_and_Philosophy" title="Anthropic Bias: Observation Selection Effects in Science and Philosophy">Anthropic Bias: Observation Selection Effects in Science and Philosophy</a></i>. In the book, he criticizes previous formulations of the anthropic principle, including those of <a href="/wiki/Brandon_Carter" title="Brandon Carter">Brandon Carter</a>, <a href="/wiki/John_A._Leslie" title="John A. Leslie">John Leslie</a>, <a href="/wiki/John_D._Barrow" title="John D. Barrow">John Barrow</a>, and <a href="/wiki/Frank_J._Tipler" title="Frank J. Tipler">Frank Tipler</a>.<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">[26]</a></sup>
</p><p>Bostrom believes that the mishandling of indexical information is a common flaw in many areas of inquiry (including cosmology, philosophy, evolution theory, game theory, and quantum physics). He argues that a theory of anthropics is needed to deal with these. He introduced the <a href="/wiki/Self-Sampling_Assumption" title="Self-Sampling Assumption" class="mw-redirect">Self-Sampling Assumption</a> (SSA) and the <a href="/wiki/Self-Indication_Assumption" title="Self-Indication Assumption" class="mw-redirect">Self-Indication Assumption</a> (SIA) and showed how they lead to different conclusions in a number of cases. He pointed out that each is affected by paradoxes or counterintuitive implications in certain thought experiments (the SSA in e.g. the Doomsday argument; the SIA in the Presumptuous Philosopher thought experiment). He suggested that a way forward may involve extending SSA into the Strong Self-Sampling Assumption (SSSA), which replaces "observers" in the SSA definition by "observer-moments". This could allow for the reference class to be relativized (and he derived an expression for this in the "observation equation").
</p><p>In later work, he has described the phenomenon of <i>anthropic shadow</i>, an observation selection effect that prevents observers from observing certain kinds of catastrophes in their recent geological and evolutionary past.<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">[27]</a></sup> Catastrophe types that lie in the anthropic shadow are likely to be underestimated unless statistical corrections are made.
</p>
<h3><span class="mw-headline" id="Ethics_of_human_enhancement">Ethics of human enhancement</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=6" title="Edit section: Ethics of human enhancement">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Bostrom is favorable towards "human enhancement", or "self-improvement and human perfectibility through the ethical application of science",<sup id="cite_ref-Guardian2006_28-0" class="reference"><a href="#cite_note-Guardian2006-28">[28]</a></sup><sup id="cite_ref-29" class="reference"><a href="#cite_note-29">[29]</a></sup> as well as a critic of bio-conservative views.<sup id="cite_ref-30" class="reference"><a href="#cite_note-30">[30]</a></sup> With philosopher Toby Ord, he proposed the <a href="/wiki/Reversal_test" title="Reversal test">reversal test</a>. Given humans' irrational status quo bias, how can one distinguish between valid criticisms of proposed changes in a human trait and criticisms merely motivated by resistance to change? The reversal test attempts to do this by asking whether it would be a good thing if the trait was altered in the opposite direction.<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">[31]</a></sup>
</p><p>In 1998, Bostrom co-founded (with <a href="/wiki/David_Pearce_(philosopher)" title="David Pearce (philosopher)">David Pearce</a>) the World <a href="/wiki/Transhumanism" title="Transhumanism">Transhumanist</a> Association<sup id="cite_ref-Guardian2006_28-1" class="reference"><a href="#cite_note-Guardian2006-28">[28]</a></sup> (which has since changed its name to <a href="/wiki/Humanity%2B" title="Humanity+">Humanity+</a>). In 2004, he co-founded (with <a href="/wiki/James_Hughes_(sociologist)" title="James Hughes (sociologist)">James Hughes</a>) the <a href="/wiki/Institute_for_Ethics_and_Emerging_Technologies" title="Institute for Ethics and Emerging Technologies">Institute for Ethics and Emerging Technologies</a>, although he is no longer involved in either of these organisations. Bostrom was named in <i><a href="/wiki/Foreign_Policy" title="Foreign Policy">Foreign Policy</a></i><span class="nowrap" style="padding-left:0.1em;">&#39;</span>s 2009 list of top global thinkers "for accepting no limits on human potential."<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">[32]</a></sup>
</p>
<h3><span class="mw-headline" id="Technology_strategy">Technology strategy</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=7" title="Edit section: Technology strategy">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>He has suggested that technology policy aimed at reducing existential risk should seek to influence the order in which various technological capabilities are attained, proposing the Principle of <a href="/wiki/Differential_Technological_Development" title="Differential Technological Development" class="mw-redirect">Differential Technological Development</a>. This principle states that we ought to retard the development of dangerous technologies, particularly ones that raise the level of existential risk, and accelerate the development of beneficial technologies, particularly those that protect against the existential risks posed by nature or by other technologies.
</p>
<h3><span class="mw-headline" id="Simulation_argument">Simulation argument</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=8" title="Edit section: Simulation argument">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<span id="Simulation_hypothesis"></span><div role="note" class="hatnote relarticle mainarticle">Main article: <a href="/wiki/Simulation_hypothesis" title="Simulation hypothesis">Simulation hypothesis</a></div>
<p>Bostrom's simulation argument posits that at least one of the following statements is very likely to be true:
</p>
<ol><li> The fraction of human-level civilizations that reach a posthuman stage is very close to zero;</li>
<li> The fraction of posthuman civilizations that are interested in running ancestor-simulations is very close to zero;</li>
<li> The fraction of all people with our kind of experiences that are living in a simulation is very close to one.</li></ol>
<p>To estimate the probability of at least one of those propositions holding, he offers the following equation:<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">[33]</a></sup>
</p>
<dl><dd><img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{sim} = \frac{f_\textrm{p}NH} {(f_\textrm{p}NH)+H}" src="//upload.wikimedia.org/math/3/e/6/3e6cab7710a0fd4f89a1d6d39ff693a7.png" /></dd></dl>
<p>where:
</p>
<dl><dd><img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{p}" src="//upload.wikimedia.org/math/3/c/1/3c1062a2cf6662fc86d4f37a92336cb3.png" /> is the fraction of all human civilizations that will reach a technological capability to program reality simulators.</dd>
<dd><img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png" /> is the average number of ancestor-simulations run by the civilizations mentioned by <img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{p}" src="//upload.wikimedia.org/math/3/c/1/3c1062a2cf6662fc86d4f37a92336cb3.png" />.</dd>
<dd><img class="mwe-math-fallback-image-inline tex" alt="H" src="//upload.wikimedia.org/math/c/1/d/c1d9f50f86825a1a2302ec2449c17196.png" /> is the average number of individuals who have lived in a civilization before it was able to perform reality simulation.</dd>
<dd><img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{sim}" src="//upload.wikimedia.org/math/0/2/b/02bfdbb30ff4b5997cf8f956647ee669.png" /> is the fraction of all humans who live in virtual realities.</dd></dl>
<p>N can be calculated by multiplying the fraction of civilizations interested in performing such simulations (<img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{1}" src="//upload.wikimedia.org/math/3/5/5/355d888660c9467289ac60905da4d9d8.png" />) by the number of simulations run by such civilizations (<img class="mwe-math-fallback-image-inline tex" alt="N_\textrm{1}" src="//upload.wikimedia.org/math/9/1/6/916e421f6bdbcc79f483337062522d1a.png" />):
</p><p><img class="mwe-math-fallback-image-inline tex" alt="N = f_\textrm{1}" src="//upload.wikimedia.org/math/d/4/a/d4a2173eddb7da0c01695f70c86d0f96.png" /><img class="mwe-math-fallback-image-inline tex" alt="N_\textrm{1}" src="//upload.wikimedia.org/math/9/1/6/916e421f6bdbcc79f483337062522d1a.png" />
</p><p>Thus the formula becomes:
</p>
<dl><dd><img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{sim} = \frac{f_\textrm{p}f_\textrm{1}N_\textrm{1}} {(f_\textrm{p}f_\textrm{1}N_\textrm{1})+1}" src="//upload.wikimedia.org/math/0/2/e/02e0e74fbc99586f1d2c64b02904814d.png" /></dd></dl>
<p>Because post-human computing power <img class="mwe-math-fallback-image-inline tex" alt="N_\textrm{1}" src="//upload.wikimedia.org/math/9/1/6/916e421f6bdbcc79f483337062522d1a.png" /> will be such a large value, at least one of the following three approximations will be true:
</p>
<dl><dd><img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{p}" src="//upload.wikimedia.org/math/3/c/1/3c1062a2cf6662fc86d4f37a92336cb3.png" /> ≈ 0</dd>
<dd><img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{1}" src="//upload.wikimedia.org/math/3/5/5/355d888660c9467289ac60905da4d9d8.png" /> ≈ 0</dd>
<dd><img class="mwe-math-fallback-image-inline tex" alt="f_\textrm{sim}" src="//upload.wikimedia.org/math/0/2/b/02bfdbb30ff4b5997cf8f956647ee669.png" /> ≈ 1</dd></dl>
<h2><span class="mw-headline" id="Policy_and_consultations">Policy and consultations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=9" title="Edit section: Policy and consultations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Bostrom has provided policy advice and consulted for an extensive range of governments and organisations. He gave evidence to the <a href="/wiki/House_of_Lords" title="House of Lords">House of Lords</a>, Select Committee on Digital Skills, with <a href="/wiki/Anders_Sandberg" title="Anders Sandberg">Anders Sandberg</a>, he was a consultant to the UK <a href="/wiki/Government_Office_for_Science" title="Government Office for Science">Government Office for Science</a> (GOSE) and Foresight for "The Future of Human Identity" report and an Expert Member for <a href="/wiki/World_Economic_Forum" title="World Economic Forum">World Economic Forum</a>'s Agenda Council for Catastrophic Risks. He is an advisory board member for the <a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a>, <a href="/wiki/Future_of_Life_Institute" title="Future of Life Institute">Future of Life Institute</a>, <a href="/wiki/Foundational_Questions_Institute" title="Foundational Questions Institute">Foundational Questions Institute</a> In Physics and Cosmology and an external advisor for the Cambridge <a href="/wiki/Centre_for_the_Study_of_Existential_Risk" title="Centre for the Study of Existential Risk">Centre for the Study of Existential Risk</a>.<sup id="cite_ref-34" class="reference"><a href="#cite_note-34">[34]</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=10" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="div-col columns column-count column-count-2" style="-moz-column-count: 2; -webkit-column-count: 2; column-count: 2;">
<ul><li> <a href="/wiki/Doomsday_argument" title="Doomsday argument">Doomsday argument</a></li>
<li> <a href="/wiki/Dream_argument" title="Dream argument">Dream argument</a></li>
<li> <a href="/wiki/Effective_altruism" title="Effective altruism">Effective altruism</a></li>
<li> <a href="/wiki/Global_catastrophic_risk" title="Global catastrophic risk">Global catastrophic risk</a></li>
<li> <a href="/wiki/Pascal%27s_mugging" title="Pascal's mugging">Pascal's mugging</a></li>
<li> <a href="/wiki/Simulation_hypothesis" title="Simulation hypothesis">Simulation hypothesis</a></li>
<li> <a href="/wiki/Simulated_reality" title="Simulated reality">Simulated reality</a></li></ul>
</div>
<h2><span class="mw-headline" id="Bibliography">Bibliography</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=11" title="Edit section: Bibliography">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Books">Books</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=12" title="Edit section: Books">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li> 2002 – <i><a href="/wiki/Anthropic_Bias:_Observation_Selection_Effects_in_Science_and_Philosophy" title="Anthropic Bias: Observation Selection Effects in Science and Philosophy">Anthropic Bias: Observation Selection Effects in Science and Philosophy</a></i>, <a href="/wiki/Special:BookSources/0415938589" class="internal mw-magiclink-isbn">ISBN 0-415-93858-9</a></li>
<li> 2009 – <i><a href="/wiki/Human_Enhancement_(book)" title="Human Enhancement (book)">Human Enhancement</a></i>, edited by Bostrom and <a href="/wiki/Julian_Savulescu" title="Julian Savulescu">Julian Savulescu</a>, <a href="/wiki/Special:BookSources/0199299722" class="internal mw-magiclink-isbn">ISBN 0-19-929972-2</a></li>
<li> 2011 – <i><a href="/wiki/Global_Catastrophic_Risks_(book)" title="Global Catastrophic Risks (book)">Global Catastrophic Risks</a></i>, edited by Bostrom and Milan M. Ćirković, <a href="/wiki/Special:BookSources/9780198570509" class="internal mw-magiclink-isbn">ISBN 978-0-19-857050-9</a></li>
<li> 2014 – <i><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></i>, <a href="/wiki/Special:BookSources/9780199678112" class="internal mw-magiclink-isbn">ISBN 978-0-19-967811-2</a></li></ul>
<h3><span class="mw-headline" id="Journal_articles_.28selected.29">Journal articles (selected)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=13" title="Edit section: Journal articles (selected)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li> <cite class="citation journal">Bostrom, Nick (1999). <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/preprints/ali/alive.html">"The Doomsday Argument is Alive and Kicking"</a>. <i>Mind</i> <b>108</b> (431): 539–550. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1093%2Fmind%2F108.431.539">10.1093/mind/108.431.539</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/2660095">2660095</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Doomsday+Argument+is+Alive+and+Kicking&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=1999&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2660095&amp;rft_id=http%3A%2F%2Fwww.anthropic-principle.com%2Fpreprints%2Fali%2Falive.html&amp;rft_id=info%3Adoi%2F10.1093%2Fmind%2F108.431.539&amp;rft.issue=431&amp;rft.jtitle=Mind&amp;rft.pages=539-550&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=108" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (January 2000). <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/preprints/rel/relative.html">"Observer-relative chances in anthropic reasoning?"</a>. <i>Erkenntnis</i> <b>52</b> (1): 93–108. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1023%2FA%3A1005551304409">10.1023/A:1005551304409</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/20012969">20012969</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Observer-relative+chances+in+anthropic+reasoning%3F&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2000-01&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F20012969&amp;rft_id=http%3A%2F%2Fwww.anthropic-principle.com%2Fpreprints%2Frel%2Frelative.html&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1005551304409&amp;rft.issue=1&amp;rft.jtitle=Erkenntnis&amp;rft.pages=93-108&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=52" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (June 2001). <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/preprints/cau/paradoxes.html">"The Doomsday Argument, Adam &amp; Eve, UN++, and Quantum Joe"</a>. <i>Synthese</i> <b>127</b> (3): 359–387. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1023%2FA%3A1010350925053">10.1023/A:1010350925053</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/20141195">20141195</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Doomsday+Argument%2C+Adam+%26+Eve%2C+UN%2B%2B%2C+and+Quantum+Joe&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2001-06&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F20141195&amp;rft_id=http%3A%2F%2Fwww.anthropic-principle.com%2Fpreprints%2Fcau%2Fparadoxes.html&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1010350925053&amp;rft.issue=3&amp;rft.jtitle=Synthese&amp;rft.pages=359-387&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=127" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (October 2001). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/newcomb.html">"The Meta-Newcomb Problem"</a>. <i>Analysis</i> <b>61</b> (4): 309–310. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1111%2F1467-8284.00310">10.1111/1467-8284.00310</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/3329010">3329010</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Meta-Newcomb+Problem&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2001-10&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F3329010&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Fnewcomb.html&amp;rft_id=info%3Adoi%2F10.1111%2F1467-8284.00310&amp;rft.issue=4&amp;rft.jtitle=Analysis&amp;rft.pages=309-310&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=61" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (March 2002). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/existential/risks.html">"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards"</a>. <i>Journal of Evolution and Technology</i> <b>9</b> (1).</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Existential+Risks%3A+Analyzing+Human+Extinction+Scenarios+and+Related+Hazards&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2002-03&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fexistential%2Frisks.html&amp;rft.issue=1&amp;rft.jtitle=Journal+of+Evolution+and+Technology&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=9" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (December 2002). <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/preprints/cos/big.html">"Self-Locating Belief in Big Worlds: Cosmology's Missing Link to Observation"</a>. <i>Journal of Philosophy</i> <b>99</b> (12): 607–623. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/3655771">3655771</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Self-Locating+Belief+in+Big+Worlds%3A+Cosmology%27s+Missing+Link+to+Observation&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2002-12&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F3655771&amp;rft_id=http%3A%2F%2Fwww.anthropic-principle.com%2Fpreprints%2Fcos%2Fbig.html&amp;rft.issue=12&amp;rft.jtitle=Journal+of+Philosophy&amp;rft.pages=607-623&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=99" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (April 2003). <a rel="nofollow" class="external text" href="http://www.simulation-argument.com/simulation.pdf">"Are You Living in a Computer Simulation?"</a> <span style="font-size:85%;">(PDF)</span>. <i>Philosophical Quarterly</i> <b>53</b> (211): 243–255. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1111%2F1467-9213.00309">10.1111/1467-9213.00309</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/3542867">3542867</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Are+You+Living+in+a+Computer+Simulation%3F&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2003-04&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F3542867&amp;rft_id=http%3A%2F%2Fwww.simulation-argument.com%2Fsimulation.pdf&amp;rft_id=info%3Adoi%2F10.1111%2F1467-9213.00309&amp;rft.issue=211&amp;rft.jtitle=Philosophical+Quarterly&amp;rft.pages=243-255&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=53" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (2003). <a rel="nofollow" class="external text" href="http://anthropic-principle.com/preprints/mys/mysteries.pdf">"The Mysteries of Self-Locating Belief and Anthropic Reasoning"</a> <span style="font-size:85%;">(PDF)</span>. <i>Harvard Review of Philosophy</i> <b>11</b> (Spring): 59–74.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Mysteries+of+Self-Locating+Belief+and+Anthropic+Reasoning&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2003&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fanthropic-principle.com%2Fpreprints%2Fmys%2Fmysteries.pdf&amp;rft.issue=Spring&amp;rft.jtitle=Harvard+Review+of+Philosophy&amp;rft.pages=59-74&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=11" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (November 2003). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/astronomical/waste.html">"Astronomical Waste: The Opportunity Cost of Delayed Technological Development"</a>. <i>Utilitas</i> <b>15</b> (3): 308–314. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1017%2FS0953820800004076">10.1017/S0953820800004076</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Astronomical+Waste%3A+The+Opportunity+Cost+of+Delayed+Technological+Development&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2003-11&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fastronomical%2Fwaste.html&amp;rft_id=info%3Adoi%2F10.1017%2FS0953820800004076&amp;rft.issue=3&amp;rft.jtitle=Utilitas&amp;rft.pages=308-314&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=15" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (May 2005). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/fable/dragon.html">"The Fable of the Dragon-Tyrant"</a>. <i>J Med Ethics</i> <b>31</b> (5): 273–277. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1136%2Fjme.2004.009035">10.1136/jme.2004.009035</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/27719395">27719395</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC1734155">1734155</a>. <a href="/wiki/PubMed_Identifier" title="PubMed Identifier" class="mw-redirect">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/15863685">15863685</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Fable+of+the+Dragon-Tyrant&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2005-05&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F27719395&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1734155&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Ffable%2Fdragon.html&amp;rft_id=info%3Adoi%2F10.1136%2Fjme.2004.009035&amp;rft_id=info%3Apmid%2F15863685&amp;rft.issue=5&amp;rft.jtitle=J+Med+Ethics&amp;rft.pages=273-277&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=31" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (June 2005). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/dignity.html">"In Defense of Posthuman Dignity"</a>. <i>Bioethics</i> <b>19</b> (3): 202–214. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1111%2Fj.1467-8519.2005.00437.x">10.1111/j.1467-8519.2005.00437.x</a>. <a href="/wiki/PubMed_Identifier" title="PubMed Identifier" class="mw-redirect">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/16167401">16167401</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=In+Defense+of+Posthuman+Dignity&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2005-06&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fethics%2Fdignity.html&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1467-8519.2005.00437.x&amp;rft_id=info%3Apmid%2F16167401&amp;rft.issue=3&amp;rft.jtitle=Bioethics&amp;rft.pages=202-214&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=19" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Tegmark, Max (December 2005). <a rel="nofollow" class="external text" href="http://arxiv.org/abs/astro-ph/0512204">"How Unlikely is a Doomsday Catastrophe?"</a>. <i>Nature</i> <b>438</b> (7069): 754. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1038%2F438754a">10.1038/438754a</a>. <a href="/wiki/PubMed_Identifier" title="PubMed Identifier" class="mw-redirect">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/16341005">16341005</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=How+Unlikely+is+a+Doomsday+Catastrophe%3F&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Tegmark%2C+Max&amp;rft.date=2005-12&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2Fastro-ph%2F0512204&amp;rft_id=info%3Adoi%2F10.1038%2F438754a&amp;rft_id=info%3Apmid%2F16341005&amp;rft.issue=7069&amp;rft.jtitle=Nature&amp;rft.pages=754&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=438" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (2006). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/fut/singleton.html">"What is a Singleton?"</a>. <i>Linguistic and Philosophical Investigations</i> <b>5</b> (2): 48–54.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=What+is+a+Singleton%3F&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2006&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Ffut%2Fsingleton.html&amp;rft.issue=2&amp;rft.jtitle=Linguistic+and+Philosophical+Investigations&amp;rft.pages=48-54&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=5" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (May 2006). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/experience.pdf">"Quantity of Experience: Brain-Duplication and Degrees of Consciousness"</a> <span style="font-size:85%;">(PDF)</span>. <i>Minds and Machines</i> <b>16</b> (2): 185–200. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1007%2Fs11023-006-9036-0">10.1007/s11023-006-9036-0</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Quantity+of+Experience%3A+Brain-Duplication+and+Degrees+of+Consciousness&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2006-05&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Fexperience.pdf&amp;rft_id=info%3Adoi%2F10.1007%2Fs11023-006-9036-0&amp;rft.issue=2&amp;rft.jtitle=Minds+and+Machines&amp;rft.pages=185-200&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=16" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Ord, Toby (July 2006). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/statusquo.pdf">"The Reversal Test: Eliminating Status Quo Bias in Applied Ethics"</a> <span style="font-size:85%;">(PDF)</span>. <i>Ethics</i> <b>116</b> (4): 656–680. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1086%2F505233">10.1086/505233</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Reversal+Test%3A+Eliminating+Status+Quo+Bias+in+Applied+Ethics&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Ord%2C+Toby&amp;rft.date=2006-07&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fethics%2Fstatusquo.pdf&amp;rft_id=info%3Adoi%2F10.1086%2F505233&amp;rft.issue=4&amp;rft.jtitle=Ethics&amp;rft.pages=656-680&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=116" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Sandberg, Anders (December 2006). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/converging.pdf">"Converging Cognitive Enhancements"</a> <span style="font-size:85%;">(PDF)</span>. <i>Annals of the New York Academy of Sciences</i> <b>1093</b> (1): 201–207. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1196%2Fannals.1382.015">10.1196/annals.1382.015</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Converging+Cognitive+Enhancements&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Sandberg%2C+Anders&amp;rft.date=2006-12&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Fconverging.pdf&amp;rft_id=info%3Adoi%2F10.1196%2Fannals.1382.015&amp;rft.issue=1&amp;rft.jtitle=Annals+of+the+New+York+Academy+of+Sciences&amp;rft.pages=201-207&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=1093" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (July 2007). <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/preprints/beauty/synthesis.pdf">"Sleeping beauty and self-location: A hybrid model"</a> <span style="font-size:85%;">(PDF)</span>. <i>Synthese</i> <b>157</b> (1): 59–78. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1007%2Fs11229-006-9010-7">10.1007/s11229-006-9010-7</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/27653543">27653543</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Sleeping+beauty+and+self-location%3A+A+hybrid+model&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2007-07&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F27653543&amp;rft_id=http%3A%2F%2Fwww.anthropic-principle.com%2Fpreprints%2Fbeauty%2Fsynthesis.pdf&amp;rft_id=info%3Adoi%2F10.1007%2Fs11229-006-9010-7&amp;rft.issue=1&amp;rft.jtitle=Synthese&amp;rft.pages=59-78&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=157" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (January 2008). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/letters/drugs.pdf">"Drugs can be used to treat more than disease"</a> <span style="font-size:85%;">(PDF)</span>. <i>Nature</i> <b>452</b> (7178): 520. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1038%2F451520b">10.1038/451520b</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Drugs+can+be+used+to+treat+more+than+disease&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2008-01&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fletters%2Fdrugs.pdf&amp;rft_id=info%3Adoi%2F10.1038%2F451520b&amp;rft.issue=7178&amp;rft.jtitle=Nature&amp;rft.pages=520&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=452" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (2008). "The doomsday argument". <i>Think</i> <b>6</b> (17–18): 23–28. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1017%2FS1477175600002943">10.1017/S1477175600002943</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+doomsday+argument&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2008&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1017%2FS1477175600002943&amp;rft.issue=17%9318&amp;rft.jtitle=Think&amp;rft.pages=23-28&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=6" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (2008). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/extraterrestrial.pdf">"Where Are They? Why I hope the search for extraterrestrial life finds nothing"</a> <span style="font-size:85%;">(PDF)</span>. <i>Technology Review</i> (May/June): 72–77.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Where+Are+They%3F+Why+I+hope+the+search+for+extraterrestrial+life+finds+nothing&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2008&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fextraterrestrial.pdf&amp;rft.issue=May%2FJune&amp;rft.jtitle=Technology+Review&amp;rft.pages=72-77&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Sandberg, Anders (September 2009). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/cognitive.pdf">"Cognitive Enhancement: Methods, Ethics, Regulatory Challenges"</a> <span style="font-size:85%;">(PDF)</span>. <i>Science and Engineering Ethics</i> <b>15</b> (3): 311–341. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1007%2Fs11948-009-9142-5">10.1007/s11948-009-9142-5</a>. <a href="/wiki/PubMed_Identifier" title="PubMed Identifier" class="mw-redirect">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/19543814">19543814</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Cognitive+Enhancement%3A+Methods%2C+Ethics%2C+Regulatory+Challenges&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Sandberg%2C+Anders&amp;rft.date=2009-09&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fcognitive.pdf&amp;rft_id=info%3Adoi%2F10.1007%2Fs11948-009-9142-5&amp;rft_id=info%3Apmid%2F19543814&amp;rft.issue=3&amp;rft.jtitle=Science+and+Engineering+Ethics&amp;rft.pages=311-341&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=15" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (2009). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/pascal.pdf">"Pascal's Mugging"</a> <span style="font-size:85%;">(PDF)</span>. <i>Analysis</i> <b>69</b> (3): 443–445. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1093%2Fanalys%2Fanp062">10.1093/analys/anp062</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/40607655">40607655</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Pascal%27s+Mugging&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2009&amp;rft.genre=article&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F40607655&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Fpascal.pdf&amp;rft_id=info%3Adoi%2F10.1093%2Fanalys%2Fanp062&amp;rft.issue=3&amp;rft.jtitle=Analysis&amp;rft.pages=443-445&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=69" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Ćirković, Milan; Sandberg, Anders (2010). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/anthropicshadow.pdf">"Anthropic Shadow: Observation Selection Effects and Human Extinction Risks"</a> <span style="font-size:85%;">(PDF)</span>. <i>Risk Analysis</i> <b>30</b> (10): 1495–1506. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1111%2Fj.1539-6924.2010.01460.x">10.1111/j.1539-6924.2010.01460.x</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Anthropic+Shadow%3A+Observation+Selection+Effects+and+Human+Extinction+Risks&amp;rft.au=%C4%86irkovi%C4%87%2C+Milan&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Sandberg%2C+Anders&amp;rft.date=2010&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Fanthropicshadow.pdf&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1539-6924.2010.01460.x&amp;rft.issue=10&amp;rft.jtitle=Risk+Analysis&amp;rft.pages=1495-1506&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=30" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (2011). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/information-hazards.pdf">"Information Hazards: A Typology of Potential Harms from Knowledge"</a> <span style="font-size:85%;">(PDF)</span>. <i>Review of Contemporary Philosophy</i> <b>10</b>: 44–79.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Information+Hazards%3A+A+Typology+of+Potential+Harms+from+Knowledge&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2011&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Finformation-hazards.pdf&amp;rft.jtitle=Review+of+Contemporary+Philosophy&amp;rft.pages=44-79&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=10" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (2011). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/infinite.pdf">"Infinite Ethics"</a> <span style="font-size:85%;">(PDF)</span>. <i>Analysis and Metaphysics</i> <b>10</b>: 9–59.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Infinite+Ethics&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2011&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fethics%2Finfinite.pdf&amp;rft.jtitle=Analysis+and+Metaphysics&amp;rft.pages=9-59&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=10" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (May 2012). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/superintelligentwill.pdf">"The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents"</a> <span style="font-size:85%;">(PDF)</span>. <i>Minds and Machines</i> <b>22</b> (2): 71–84. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1007%2Fs11023-012-9281-3">10.1007/s11023-012-9281-3</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Superintelligent+Will%3A+Motivation+and+Instrumental+Rationality+in+Advanced+Artificial+Agents&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2012-05&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fsuperintelligentwill.pdf&amp;rft_id=info%3Adoi%2F10.1007%2Fs11023-012-9281-3&amp;rft.issue=2&amp;rft.jtitle=Minds+and+Machines&amp;rft.pages=71-84&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=22" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Shulman, Carl (2012). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/aievolution.pdf">"How Hard is AI? Evolutionary Arguments and Selection Effects"</a> <span style="font-size:85%;">(PDF)</span>. <i>J. Consciousness Studies</i> <b>19</b> (7–8): 103–130.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=How+Hard+is+AI%3F+Evolutionary+Arguments+and+Selection+Effects&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Shulman%2C+Carl&amp;rft.date=2012&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Faievolution.pdf&amp;rft.issue=7%938&amp;rft.jtitle=J.+Consciousness+Studies&amp;rft.pages=103-130&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=19" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Armstrong, Stuart; Sandberg, Anders (November 2012). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/oracle.pdf">"Thinking Inside the Box: Controlling and Using Oracle AI"</a> <span style="font-size:85%;">(PDF)</span>. <i>Minds and Machines</i> <b>22</b> (4): 299–324. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1007%2Fs11023-012-9282-2">10.1007/s11023-012-9282-2</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Thinking+Inside+the+Box%3A+Controlling+and+Using+Oracle+AI&amp;rft.au=Armstrong%2C+Stuart&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Sandberg%2C+Anders&amp;rft.date=2012-11&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Foracle.pdf&amp;rft_id=info%3Adoi%2F10.1007%2Fs11023-012-9282-2&amp;rft.issue=4&amp;rft.jtitle=Minds+and+Machines&amp;rft.pages=299-324&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=22" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick (February 2013). <a rel="nofollow" class="external text" href="http://www.existential-risk.org/concept.html">"Existential Risk Reduction as Global Priority"</a>. <i>Global Policy</i> <b>4</b> (3): 15–31. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1111%2F1758-5899.12002">10.1111/1758-5899.12002</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Existential+Risk+Reduction+as+Global+Priority&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2013-02&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.existential-risk.org%2Fconcept.html&amp;rft_id=info%3Adoi%2F10.1111%2F1758-5899.12002&amp;rft.issue=3&amp;rft.jtitle=Global+Policy&amp;rft.pages=15-31&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=4" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Shulman, Carl (February 2014). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/embryo.pdf">"Embryo Selection for Cognitive Enhancement: Curiosity or Game-changer?"</a> <span style="font-size:85%;">(PDF)</span>. <i>Global Policy</i> <b>5</b> (1): 85–92. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1111%2F1758-5899.12123">10.1111/1758-5899.12123</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Embryo+Selection+for+Cognitive+Enhancement%3A+Curiosity+or+Game-changer%3F&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Shulman%2C+Carl&amp;rft.date=2014-02&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Fembryo.pdf&amp;rft_id=info%3Adoi%2F10.1111%2F1758-5899.12123&amp;rft.issue=1&amp;rft.jtitle=Global+Policy&amp;rft.pages=85-92&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=5" class="Z3988"><span style="display:none;">&#160;</span></span></li>
<li> <cite class="citation journal">Bostrom, Nick; Muehlhauser, Luke (2014). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/views/whyfriendlyai.pdf">"Why we need friendly AI"</a> <span style="font-size:85%;">(PDF)</span>. <i>Think</i> <b>13</b> (36): 41–47. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1017%2FS1477175613000316">10.1017/S1477175613000316</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Why+we+need+friendly+AI&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Muehlhauser%2C+Luke&amp;rft.date=2014&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fviews%2Fwhyfriendlyai.pdf&amp;rft_id=info%3Adoi%2F10.1017%2FS1477175613000316&amp;rft.issue=36&amp;rft.jtitle=Think&amp;rft.pages=41-47&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=13" class="Z3988"><span style="display:none;">&#160;</span></span></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=14" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/cv.html">"nickbostrom.com"</a>. Nickbostrom.com<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=nickbostrom.com&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fcv.html&amp;rft.pub=Nickbostrom.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.oxfordmartin.ox.ac.uk/people/22">"Professor Nick Bostrom&#160;: People"</a>. Oxford Martin School<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Professor+Nick+Bostrom+%3A+People&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.oxfordmartin.ox.ac.uk%2Fpeople%2F22&amp;rft.pub=Oxford+Martin+School&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.fhi.ox.ac.uk/">"Future of Humanity Institute – University of Oxford"</a>. Fhi.ox.ac.uk<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Future+of+Humanity+Institute+%93+University+of+Oxford&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.fhi.ox.ac.uk%2F&amp;rft.pub=Fhi.ox.ac.uk&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://blog.oup.com/2014/04/is-transcendence-possible-the-science-behind-the-film/">"The viability of Transcendence: the science behind the film"</a>. <i>OUPblog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+viability+of+Transcendence%3A+the+science+behind+the+film&amp;rft.genre=unknown&amp;rft_id=https%3A%2F%2Fblog.oup.com%2F2014%2F04%2Fis-transcendence-possible-the-science-behind-the-film%2F&amp;rft.jtitle=OUPblog&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nytimes.com/2014/09/09/science/best-selling-science-books.html?module=Search&amp;mabReward=relbias%3As&amp;_r=0">"Best Selling Science Books"</a>. <i>The New York Times</i><span class="reference-accessdate">. Retrieved <span class="nowrap">19 February</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Best+Selling+Science+Books&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nytimes.com%2F2014%2F09%2F09%2Fscience%2Fbest-selling-science-books.html%3Fmodule%3DSearch%26mabReward%3Drelbias%253As%26_r%3D0&amp;rft.jtitle=The+New+York+Times&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-Oxford_University_Press-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-Oxford_University_Press_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Oxford_University_Press_6-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://blog.oup.com/2014/09/interview-nick-bostrom-superintelligence/">"Nick Bostrom on artificial intelligence"</a>. Oxford University Press. 8 September 2014<span class="reference-accessdate">. Retrieved <span class="nowrap">4 March</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Nick+Bostrom+on+artificial+intelligence&amp;rft.date=2014-09-08&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fblog.oup.com%2F2014%2F09%2Finterview-nick-bostrom-superintelligence%2F&amp;rft.pub=Oxford+University+Press&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><cite class="citation web">Frankel, Rebecca. <a rel="nofollow" class="external text" href="http://foreignpolicy.com/2009/11/25/the-fp-top-100-global-thinkers-7/">"The FP Top 100 Global Thinkers"</a>. <i>Foreign Policy</i><span class="reference-accessdate">. Retrieved <span class="nowrap">5 September</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+FP+Top+100+Global+Thinkers&amp;rft.aufirst=Rebecca&amp;rft.aulast=Frankel&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fforeignpolicy.com%2F2009%2F11%2F25%2Fthe-fp-top-100-global-thinkers-7%2F&amp;rft.jtitle=Foreign+Policy&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://2015globalthinkers.foreignpolicy.com/#advocates/detail/bostrom">"Nick Bostrom: For sounding the alarm on our future computer overlords."</a>. <i>foreignpolicy.com</i>. Foreign Policy magazine<span class="reference-accessdate">. Retrieved <span class="nowrap">1 December</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Nick+Bostrom%3A+For+sounding+the+alarm+on+our+future+computer+overlords.&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2F2015globalthinkers.foreignpolicy.com%2F%23advocates%2Fdetail%2Fbostrom&amp;rft.jtitle=foreignpolicy.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.forbes.com/sites/ericmack/2015/01/28/bill-gates-also-worries-artificial-intelligence-is-a-threat/">"Forbes"</a>. Forbes<span class="reference-accessdate">. Retrieved <span class="nowrap">19 February</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Forbes&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.forbes.com%2Fsites%2Fericmack%2F2015%2F01%2F28%2Fbill-gates-also-worries-artificial-intelligence-is-a-threat%2F&amp;rft.pub=Forbes&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.thefiscaltimes.com/2015/01/28/Bill-Gates-Worried-About-Rise-Machines">"Bill Gates Is Worried About the Rise of the Machines"</a>. <i>The Fiscal Times</i><span class="reference-accessdate">. Retrieved <span class="nowrap">19 February</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Bill+Gates+Is+Worried+About+the+Rise+of+the+Machines&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.thefiscaltimes.com%2F2015%2F01%2F28%2FBill-Gates-Worried-About-Rise-Machines&amp;rft.jtitle=The+Fiscal+Times&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><cite class="citation web">Bratton, Benjamin H. (23 February 2015). <a rel="nofollow" class="external text" href="http://opinionator.blogs.nytimes.com/2015/02/23/outing-a-i-beyond-the-turing-test/?_r=0">"Outing A.I.: Beyond the Turing Test"</a>. <i>The New York Times</i><span class="reference-accessdate">. Retrieved <span class="nowrap">4 March</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Outing+A.I.%3A+Beyond+the+Turing+Test&amp;rft.aufirst=Benjamin+H.&amp;rft.aulast=Bratton&amp;rft.date=2015-02-23&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fopinionator.blogs.nytimes.com%2F2015%2F02%2F23%2Fouting-a-i-beyond-the-turing-test%2F%3F_r%3D0&amp;rft.jtitle=The+New+York+Times&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/">"Nick Bostrom home page"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">22 July</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Nick+Bostrom+home+page&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2F&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-newyorker-13"><span class="mw-cite-backlink">^ <a href="#cite_ref-newyorker_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-newyorker_13-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-newyorker_13-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Khatchadourian, Raffi (23 November 2015). <a rel="nofollow" class="external text" href="http://www.newyorker.com/magazine/2015/11/23/doomsday-invention-artificial-intelligence-nick-bostrom">"The Doomsday Invention"</a>. <i><a href="/wiki/The_New_Yorker" title="The New Yorker">The New Yorker</a></i> (Condé Nast) <b>XCI</b> (37): 64–79. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0028-792X">0028-792X</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Doomsday+Invention&amp;rft.aufirst=Raffi&amp;rft.aulast=Khatchadourian&amp;rft.date=2015-11-23&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.newyorker.com%2Fmagazine%2F2015%2F11%2F23%2Fdoomsday-invention-artificial-intelligence-nick-bostrom&amp;rft.issn=0028-792X&amp;rft.issue=37&amp;rft.jtitle=The+New+Yorker&amp;rft.pages=64-79&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=XCI" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/cv.pdf">"Nick Bostrom&#160;: CV"</a> <span style="font-size:85%;">(PDF)</span>. Nickbostrom.com<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Nick+Bostrom+%3A+CV&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fcv.pdf&amp;rft.pub=Nickbostrom.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bostrom, Nick (March 2002). <a rel="nofollow" class="external text" href="http://www.jetpress.org/volume9/risks.html">"Existential Risks"</a>. <i><a href="/wiki/Journal_of_Evolution_and_Technology" title="Journal of Evolution and Technology" class="mw-redirect">Journal of Evolution and Technology</a></i> <b>9</b>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Existential+Risks&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2002-03&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.jetpress.org%2Fvolume9%2Frisks.html&amp;rft.jtitle=Journal+of+Evolution+and+Technology&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=9" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-Andersen-16"><span class="mw-cite-backlink">^ <a href="#cite_ref-Andersen_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Andersen_16-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation web">Andersen, Ross. <a rel="nofollow" class="external text" href="http://aeon.co/magazine/philosophy/ross-andersen-human-extinction/">"Omens"</a>. Aeon Media Ltd<span class="reference-accessdate">. Retrieved <span class="nowrap">5 September</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.aufirst=Ross&amp;rft.aulast=Andersen&amp;rft.btitle=Omens&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Faeon.co%2Fmagazine%2Fphilosophy%2Fross-andersen-human-extinction%2F&amp;rft.pub=Aeon+Media+Ltd.&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation journal"><a href="/wiki/Max_Tegmark" title="Max Tegmark">Tegmark, Max</a>; Bostrom, Nick (2005). <a rel="nofollow" class="external text" href="http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0019/5923/How_Unlikely_is_a_Doomsday_Catastrophe_plus_Supplementary_Materials.pdf">"Astrophysics: is a doomsday catastrophe likely?"</a> <span style="font-size:85%;">(PDF)</span>. <i>Nature</i> <b>438</b> (7069): 754. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1038%2F438754a">10.1038/438754a</a>. <a href="/wiki/PubMed_Identifier" title="PubMed Identifier" class="mw-redirect">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/16341005">16341005</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Astrophysics%3A+is+a+doomsday+catastrophe+likely%3F&amp;rft.au=Bostrom%2C+Nick&amp;rft.aufirst=Max&amp;rft.aulast=Tegmark&amp;rft.date=2005&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.fhi.ox.ac.uk%2F&#95;_data%2Fassets%2Fpdf_file%2F0019%2F5923%2FHow_Unlikely_is_a_Doomsday_Catastrophe_plus_Supplementary_Materials.pdf&amp;rft_id=info%3Adoi%2F10.1038%2F438754a&amp;rft_id=info%3Apmid%2F16341005&amp;rft.issue=7069&amp;rft.jtitle=Nature&amp;rft.pages=754&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=438" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bostrom, Nick (May–June 2008). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/extraterrestrial.pdf">"Where are they? Why I Hope the Search for Extraterrestrial Life Finds Nothing"</a> <span style="font-size:85%;">(PDF)</span>. <i>MIT Technology Review</i>: 72–77.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Where+are+they%3F+Why+I+Hope+the+Search+for+Extraterrestrial+Life+Finds+Nothing&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2008-05%2F2008-06&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fextraterrestrial.pdf&amp;rft.jtitle=MIT+Technology+Review&amp;rft.pages=72-77&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-NYT-20150803-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-NYT-20150803_19-0">^</a></b></span> <span class="reference-text"><cite class="citation news"><a href="/wiki/Dennis_Overbye" title="Dennis Overbye">Overbye, Dennis</a> (August 3, 2015). <a rel="nofollow" class="external text" href="http://www.nytimes.com/2015/08/04/science/space/the-flip-side-of-optimism-about-life-on-other-planets.html">"The Flip Side of Optimism About Life on Other Planets"</a>. <i><a href="/wiki/The_New_York_Times" title="The New York Times">The New York Times</a></i><span class="reference-accessdate">. Retrieved <span class="nowrap">October 29,</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+Flip+Side+of+Optimism+About+Life+on+Other+Planets&amp;rft.aufirst=Dennis&amp;rft.aulast=Overbye&amp;rft.date=2015-08-03&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nytimes.com%2F2015%2F08%2F04%2Fscience%2Fspace%2Fthe-flip-side-of-optimism-about-life-on-other-planets.html&amp;rft.jtitle=The+New+York+Times&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.existential-risk.org/concept.pdf">"Existential Risk Prevention as Global Priority"</a> <span style="font-size:85%;">(PDF)</span>. Nickbostrom.com<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Existential+Risk+Prevention+as+Global+Priority&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.existential-risk.org%2Fconcept.pdf&amp;rft.pub=Nickbostrom.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><cite class="citation book">Parfit, Derek (1984). <i>Reasons and Persons</i>. Oxford, England: Oxford University Press. pp.&#160;453–454. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/019824908X" title="Special:BookSources/019824908X">019824908X</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.aufirst=Derek&amp;rft.aulast=Parfit&amp;rft.btitle=Reasons+and+Persons&amp;rft.date=1984&amp;rft.genre=book&amp;rft.isbn=019824908X&amp;rft.pages=453-454&amp;rft.place=Oxford%2C+England&amp;rft.pub=Oxford+University+Press&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/astronomical/waste.html">"Astronomical Waste: The Opportunity Cost of Delayed Technological Development"</a>. Nickbostrom.com<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Astronomical+Waste%3A+The+Opportunity+Cost+of+Delayed+Technological+Development&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fastronomical%2Fwaste.html&amp;rft.pub=Nickbostrom.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/existential/risks.html">"Existential Risks: Analyzing Human Extinction Scenarios"</a>. Nickbostrom.com<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Existential+Risks%3A+Analyzing+Human+Extinction+Scenarios&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fexistential%2Frisks.html&amp;rft.pub=Nickbostrom.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://futureoflife.org/misc/open_letter">"The Future of Life Institute Open Letter"</a>. The Future of Life Institute<span class="reference-accessdate">. Retrieved <span class="nowrap">4 March</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=The+Future+of+Life+Institute+Open+Letter&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Ffutureoflife.org%2Fmisc%2Fopen_letter&amp;rft.pub=The+Future+of+Life+Institute&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.ft.com/cms/s/0/3d2c2f12-99e9-11e4-93c1-00144feabdc0.html#axzz3TNL9lxJV">"Scientists and investors warn on AI"</a>. <i>The Financial Times</i><span class="reference-accessdate">. Retrieved <span class="nowrap">4 March</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Scientists+and+investors+warn+on+AI&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.ft.com%2Fcms%2Fs%2F0%2F3d2c2f12-99e9-11e4-93c1-00144feabdc0.html%23axzz3TNL9lxJV&amp;rft.jtitle=The+Financial+Times&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation book">Bostrom, Nick (2002). <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/sites/anthropic-principle.com/files/pdfs/anthropicbias.pdf"><i>Anthropic Bias: Observation Selection Effects in Science and Philosophy</i></a> <span style="font-size:85%;">(PDF)</span>. New York: Routledge. pp.&#160;44–58. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-415-93858-9" title="Special:BookSources/0-415-93858-9">0-415-93858-9</a><span class="reference-accessdate">. Retrieved <span class="nowrap">22 July</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.btitle=Anthropic+Bias%3A+Observation+Selection+Effects+in+Science+and+Philosophy&amp;rft.date=2002&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fwww.anthropic-principle.com%2Fsites%2Fanthropic-principle.com%2Ffiles%2Fpdfs%2Fanthropicbias.pdf&amp;rft.isbn=0-415-93858-9&amp;rft.pages=44-58&amp;rft.place=New+York&amp;rft.pub=Routledge&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/papers/anthropicshadow.pdf">"Anthropic Shadow: Observation Selection Effects and Human Extinction Risks"</a> <span style="font-size:85%;">(PDF)</span>. Nickbostrom.com<span class="reference-accessdate">. Retrieved <span class="nowrap">16 October</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=Anthropic+Shadow%3A+Observation+Selection+Effects+and+Human+Extinction+Risks&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fpapers%2Fanthropicshadow.pdf&amp;rft.pub=Nickbostrom.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-Guardian2006-28"><span class="mw-cite-backlink">^ <a href="#cite_ref-Guardian2006_28-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Guardian2006_28-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation news">Sutherland, John (9 May 2006). <a rel="nofollow" class="external text" href="http://www.guardian.co.uk/science/2006/may/09/academicexperts.genetics">"The ideas interview: Nick Bostrom; John Sutherland meets a transhumanist who wrestles with the ethics of technologically enhanced human beings"</a>. <i><a href="/wiki/The_Guardian" title="The Guardian">The Guardian</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+ideas+interview%3A+Nick+Bostrom%3B+John+Sutherland+meets+a+transhumanist+who+wrestles+with+the+ethics+of+technologically+enhanced+human+beings&amp;rft.aufirst=John&amp;rft.aulast=Sutherland&amp;rft.date=2006-05-09&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.guardian.co.uk%2Fscience%2F2006%2Fmay%2F09%2Facademicexperts.genetics&amp;rft.jtitle=The+Guardian&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bostrom, Nick (2003). <a rel="nofollow" class="external text" href="http://cyber.law.harvard.edu/cyberlaw2005/sites/cyberlaw2005/images/Transhumanist_Perspective.pdf">"Human Genetic Enhancements: A Transhumanist Perspective"</a> <span style="font-size:85%;">(PDF)</span>. <i>Journal of Value Inquiry</i> <b>37</b> (4): 493–506. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1023%2FB%3AINQU.0000019037.67783.d5">10.1023/B:INQU.0000019037.67783.d5</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=Human+Genetic+Enhancements%3A+A+Transhumanist+Perspective&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2003&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fcyber.law.harvard.edu%2Fcyberlaw2005%2Fsites%2Fcyberlaw2005%2Fimages%2FTranshumanist_Perspective.pdf&amp;rft_id=info%3Adoi%2F10.1023%2FB%3AINQU.0000019037.67783.d5&amp;rft.issue=4&amp;rft.jtitle=Journal+of+Value+Inquiry&amp;rft.pages=493-506&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=37" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bostrom, Nick (2005). "In Defence of Posthuman Dignity". <i>Bioethics</i> <b>19</b> (3): 202–214. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1111%2Fj.1467-8519.2005.00437.x">10.1111/j.1467-8519.2005.00437.x</a>. <a href="/wiki/PubMed_Identifier" title="PubMed Identifier" class="mw-redirect">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/16167401">16167401</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=In+Defence+of+Posthuman+Dignity&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.date=2005&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1467-8519.2005.00437.x&amp;rft_id=info%3Apmid%2F16167401&amp;rft.issue=3&amp;rft.jtitle=Bioethics&amp;rft.pages=202-214&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=19" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bostrom, Nick; Ord, Toby (2006). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/statusquo.pdf">"The reversal test: eliminating status quo bias in applied ethics"</a> <span style="font-size:85%;">(PDF)</span>. <i>Ethics</i> <b>116</b> (4): 656–679. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//dx.doi.org/10.1086%2F505233">10.1086/505233</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+reversal+test%3A+eliminating+status+quo+bias+in+applied+ethics&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.au=Ord%2C+Toby&amp;rft.date=2006&amp;rft.genre=article&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fethics%2Fstatusquo.pdf&amp;rft_id=info%3Adoi%2F10.1086%2F505233&amp;rft.issue=4&amp;rft.jtitle=Ethics&amp;rft.pages=656-679&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=116" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.foreignpolicy.com/articles/2009/11/30/the_fp_top_100_global_thinkers?page=0,30">"The FP Top 100 Global Thinkers – 73. Nick Bostrom"</a>. <i><a href="/wiki/Foreign_Policy" title="Foreign Policy">Foreign Policy</a></i>. December 2009.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.atitle=The+FP+Top+100+Global+Thinkers+%93+73.+Nick+Bostrom&amp;rft.date=2009-12&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.foreignpolicy.com%2Farticles%2F2009%2F11%2F30%2Fthe_fp_top_100_global_thinkers%3Fpage%3D0%2C30&amp;rft.jtitle=Foreign+Policy&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><cite class="citation web">Bostrom, Nick (19 January 2010). <a rel="nofollow" class="external text" href="http://www.simulation-argument.com/simulation.html">"Are You Living in a Computer Simulation?"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.aufirst=Nick&amp;rft.aulast=Bostrom&amp;rft.btitle=Are+You+Living+in+a+Computer+Simulation%3F&amp;rft.date=2010-01-19&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.simulation-argument.com%2Fsimulation.html&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/cv.html">"nickbostrom.com"</a>. Nickbostrom.com<span class="reference-accessdate">. Retrieved <span class="nowrap">19 February</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANick+Bostrom&amp;rft.btitle=nickbostrom.com&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fcv.html&amp;rft.pub=Nickbostrom.com&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span>
</li>
</ol></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Nick_Bostrom&amp;action=edit&amp;section=15" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="mbox-small plainlinks sistersitebox" style="border:1px solid #aaa;background-color:#f9f9f9">
<tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png" width="30" height="40" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/45px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/59px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376" /></td>
<td class="mbox-text plainlist">Wikimedia Commons has media related to <i><b><a href="//commons.wikimedia.org/wiki/Category:Nick_Bostrom" class="extiw" title="commons:Category:Nick Bostrom">Nick Bostrom</a></b></i>.</td></tr></table>
<ul><li> <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/">Nick Bostrom home page</a></li>
<li> <a rel="nofollow" class="external text" href="http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111"><i>Superintelligence: Paths, Dangers, Strategies</i></a></li>
<li> Bostrom's <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/">Anthropic Principle website</a>, containing information about the <a href="/wiki/Anthropic_principle" title="Anthropic principle">anthropic principle</a> and the <a href="/wiki/Doomsday_argument" title="Doomsday argument">Doomsday argument</a>.</li>
<li> Online copy of book, "Anthropic Bias: Observation Selection Effects in Science and Philosophy" (<a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/book/anthropicbias.html">HTML</a>, <a rel="nofollow" class="external text" href="http://www.anthropic-principle.com/book/anthropicbias.pdf">PDF</a>)</li>
<li> Bostrom's <a rel="nofollow" class="external text" href="http://www.simulation-argument.com/">Simulation Argument website</a></li>
<li> Bostrom's <a rel="nofollow" class="external text" href="http://www.existential-risk.org/">Existential Risk website</a></li>
<li> <a rel="nofollow" class="external text" href="http://www.imdb.com/name/nm1580947/">Nick Bostrom</a> at the <a href="/wiki/IMDb" title="IMDb">Internet Movie Database</a></li>
<li> <a rel="nofollow" class="external text" href="http://twit.tv/shows/triangulation/episodes/177/">Nick Bostrom</a> interviewed on the TV show Triangulation on the <a href="/wiki/TWiT.tv" title="TWiT.tv">TWiT.tv</a> network</li>
<li> <a rel="nofollow" class="external text" href="https://www.ted.com/speakers/nick_bostrom">Nick Bostrom</a> at <a href="/wiki/TED_(conference)" title="TED (conference)">TED</a></li>
<li> <a rel="nofollow" class="external text" href="https://www.hottopics.ht/stories/lists/10-global-thinkers-concerned-with-the-ethics-of-ai/">The 10 gatekeepers of humanity against the risks of AI</a>, <i>Hot Topics 2015</i></li>
<li> <a rel="nofollow" class="external text" href="http://www.washingtonpost.com/sf/national/2015/12/27/aianxiety/">The A.I. anxiety</a> <i><a href="/wiki/The_Washington_Post" title="The Washington Post">The Washington Post</a></i>, <i>December 27, 2015</i>.</li></ul>
<table class="navbox" style="border-spacing:0"><tr><td style="padding:2px"><table class="nowraplinks collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Future_of_Humanity_Institute" title="Template:Future of Humanity Institute"><abbr title="View this template" style=";;background:none transparent;border:none;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Future_of_Humanity_Institute" title="Template talk:Future of Humanity Institute"><abbr title="Discuss this template" style=";;background:none transparent;border:none;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Future_of_Humanity_Institute&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;">e</abbr></a></li></ul></div><div style="font-size:114%"><a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a></div></th></tr><tr style="height:2px"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">People</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li> <strong class="selflink">Nick Bostrom</strong></li>
<li> <a href="/wiki/Anders_Sandberg" title="Anders Sandberg">Anders Sandberg</a></li>
<li> <a href="/wiki/Toby_Ord" title="Toby Ord">Toby Ord</a></li>
<li> <a href="/wiki/K._Eric_Drexler" title="K. Eric Drexler">K. Eric Drexler</a></li>
<li> <a href="/wiki/Robin_Hanson" title="Robin Hanson">Robin Hanson</a></li></ul>
</div></td></tr><tr style="height:2px"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Concepts</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li> <a href="/wiki/Global_catastrophic_risk" title="Global catastrophic risk">Global catastrophic risk</a></li>
<li> <a href="/wiki/Simulation_hypothesis" title="Simulation hypothesis">Simulation hypothesis</a></li>
<li> <a href="/wiki/Reversal_test" title="Reversal test">Reversal test</a></li>
<li> <a href="/wiki/Self-indication_assumption" title="Self-indication assumption">Self-indication assumption</a></li>
<li> <a href="/wiki/Self-sampling_assumption" title="Self-sampling assumption">Self-sampling assumption</a></li>
<li> <a href="/wiki/Pascal%27s_mugging" title="Pascal's mugging">Pascal's mugging</a></li>
<li> <a href="/wiki/Differential_technological_development" title="Differential technological development">Differential technological development</a></li>
<li> <a href="/wiki/Singleton_(global_governance)" title="Singleton (global governance)">Singleton</a></li>
<li> <a href="/wiki/Great_Filter" title="Great Filter">Great Filter</a></li></ul>
</div></td></tr><tr style="height:2px"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Works</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li> <a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></li>
<li> <a href="/wiki/Global_Catastrophic_Risks_(book)" title="Global Catastrophic Risks (book)">Global Catastrophic Risks (book)</a></li>
<li> <a href="/wiki/Human_Enhancement_(book)" title="Human Enhancement (book)">Human Enhancement (book)</a></li>
<li> <a href="/wiki/Anthropic_Bias:_Observation_Selection_Effects_in_Science_and_Philosophy" title="Anthropic Bias: Observation Selection Effects in Science and Philosophy">Anthropic Bias: Observation Selection Effects in Science and Philosophy</a></li></ul>
</div></td></tr><tr style="height:2px"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Related<br/>organizations</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li> <a href="/wiki/Centre_for_the_Study_of_Existential_Risk" title="Centre for the Study of Existential Risk">Centre for the Study of Existential Risk</a></li>
<li> <a href="/wiki/Future_of_Life_Institute" title="Future of Life Institute">Future of Life Institute</a></li>
<li> <a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a></li>
<li> <a href="/wiki/Humanity%2B" title="Humanity+">Humanity+</a></li>
<li> <a href="/wiki/Institute_for_Ethics_and_Emerging_Technologies" title="Institute for Ethics and Emerging Technologies">Institute for Ethics and Emerging Technologies</a></li>
<li> <a href="/wiki/Foundational_Questions_Institute" title="Foundational Questions Institute">Foundational Questions Institute</a></li></ul>
</div></td></tr></table></td></tr></table>
<table class="navbox" style="border-spacing:0"><tr><td style="padding:2px"><table class="nowraplinks collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Existential_risk_from_artificial_intelligence" title="Template:Existential risk from artificial intelligence"><abbr title="View this template" style=";;background:none transparent;border:none;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Existential_risk_from_artificial_intelligence" title="Template talk:Existential risk from artificial intelligence"><abbr title="Discuss this template" style=";;background:none transparent;border:none;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Existential_risk_from_artificial_intelligence&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;">e</abbr></a></li></ul></div><div style="font-size:114%"><a href="/wiki/Existential_risk_from_advanced_artificial_intelligence" title="Existential risk from advanced artificial intelligence" class="mw-redirect">Existential risk from advanced artificial intelligence</a></div></th></tr><tr style="height:2px"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Concepts</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li> <a href="/wiki/AI_box" title="AI box">AI box</a></li>
<li> <a href="/wiki/AI_takeover" title="AI takeover">AI takeover</a></li>
<li> <a href="/wiki/Friendly_artificial_intelligence" title="Friendly artificial intelligence">Friendly artificial intelligence</a></li>
<li> <a href="/wiki/Instrumental_convergence" title="Instrumental convergence">Instrumental convergence</a></li>
<li> <a href="/wiki/Intelligence_explosion" title="Intelligence explosion">Intelligence explosion</a></li>
<li> <a href="/wiki/Machine_ethics" title="Machine ethics">Machine ethics</a></li>
<li> <a href="/wiki/Recursive_self-improvement" title="Recursive self-improvement">Recursive self-improvement</a></li>
<li> <a href="/wiki/Superintelligence" title="Superintelligence">Superintelligence</a></li>
<li> <a href="/wiki/Technological_singularity" title="Technological singularity">Technological singularity</a></li></ul>
</div></td></tr><tr style="height:2px"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Organizations</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li> <a href="/wiki/Centre_for_the_Study_of_Existential_Risk" title="Centre for the Study of Existential Risk">Centre for the Study of Existential Risk</a></li>
<li> <a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a></li>
<li> <a href="/wiki/Future_of_Life_Institute" title="Future of Life Institute">Future of Life Institute</a></li>
<li> <a href="/wiki/Global_Catastrophic_Risk_Institute" title="Global Catastrophic Risk Institute">Global Catastrophic Risk Institute</a></li>
<li> <a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a></li>
<li> <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a></li></ul>
</div></td></tr><tr style="height:2px"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Other</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><a href="/wiki/Open_Letter_on_Artificial_Intelligence" title="Open Letter on Artificial Intelligence">Open Letter on Artificial Intelligence</a>, <a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">Ethics of artificial intelligence</a>, <a href="/wiki/Artificial_general_intelligence#Controversies_and_dangers" title="Artificial general intelligence">Controversies and dangers of artificial general intelligence</a>, <a href="/wiki/Global_catastrophic_risk#Artificial_intelligence" title="Global catastrophic risk">Artificial intelligence as a global catastrophic risk</a>, <i><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></i>, <i><a href="/wiki/Our_Final_Invention" title="Our Final Invention">Our Final Invention</a></i></div></td></tr></table></td></tr></table>
<table class="navbox" style="border-spacing:0"><tr><td style="padding:2px"><table class="nowraplinks hlist navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tr><th scope="row" class="navbox-group"><a href="/wiki/Help:Authority_control" title="Help:Authority control">Authority control</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li>  <a rel="nofollow" class="external text" href="//www.worldcat.org/identities/containsVIAFID/7723572">WorldCat Identities</a></li>
<li> <a href="/wiki/Virtual_International_Authority_File" title="Virtual International Authority File">VIAF</a>: <span class="uid"><a rel="nofollow" class="external text" href="https://viaf.org/viaf/7723572">7723572</a></span></li>
<li> <a href="/wiki/Library_of_Congress_Control_Number" title="Library of Congress Control Number">LCCN</a>: <span class="uid"><a rel="nofollow" class="external text" href="http://id.loc.gov/authorities/names/n2001093242">n2001093242</a></span></li>
<li> <a href="/wiki/International_Standard_Name_Identifier" title="International Standard Name Identifier">ISNI</a>: <span class="uid"><a rel="nofollow" class="external text" href="http://isni.org/isni/0000000122761693">0000 0001 2276 1693</a></span></li>
<li> <a href="/wiki/Integrated_Authority_File" title="Integrated Authority File">GND</a>: <span class="uid"><a rel="nofollow" class="external text" href="http://d-nb.info/gnd/135992451">135992451</a></span></li>
<li> <a href="/wiki/Syst%C3%A8me_universitaire_de_documentation" title="Système universitaire de documentation">SUDOC</a>: <span class="uid"><a rel="nofollow" class="external text" href="http://www.idref.fr/129852945">129852945</a></span></li>
<li> <a href="/wiki/Biblioth%C3%A8que_nationale_de_France" title="Bibliothèque nationale de France">BNF</a>: <span class="uid"><a rel="nofollow" class="external text" href="http://catalogue.bnf.fr/ark:/12148/cb15907251j">cb15907251j</a> <a rel="nofollow" class="external text" href="http://data.bnf.fr/ark:/12148/cb15907251j">(data)</a></span></li>
<li> <a href="/wiki/National_Library_of_the_Czech_Republic" title="National Library of the Czech Republic">NKC</a>: <span class="uid"><a rel="nofollow" class="external text" href="http://aleph.nkp.cz/F/?func=find-c&amp;local_base=aut&amp;ccl_term=ica=jx20100831002&amp;CON_LNG=ENG">jx20100831002</a></span></li></ul>
</div></td></tr></table></td></tr></table>
